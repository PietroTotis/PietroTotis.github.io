<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Article-Journal | Pietro Totis</title>
    <link>http://localhost:41063/publication_types/article-journal/</link>
      <atom:link href="http://localhost:41063/publication_types/article-journal/index.xml" rel="self" type="application/rss+xml" />
    <description>Article-Journal</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 09 Nov 2022 15:45:40 +0100</lastBuildDate>
    <image>
      <url>http://localhost:41063/media/icon_hu_645fa481986063ef.png</url>
      <title>Article-Journal</title>
      <link>http://localhost:41063/publication_types/article-journal/</link>
    </image>
    
    <item>
      <title>Lifted Reasoning for Combinatorial Counting</title>
      <link>http://localhost:41063/publication/coso/</link>
      <pubDate>Wed, 09 Nov 2022 15:45:40 +0100</pubDate>
      <guid>http://localhost:41063/publication/coso/</guid>
      <description>&lt;h3 id=&#34;problem-combinatorics-math-word-problems&#34;&gt;Problem: combinatorics math word problems&lt;/h3&gt;
&lt;p&gt;Combinatorics math word problems sketch in natural language a configuration of a finite set of objects and (possibly) some constraints. The task is to &lt;em&gt;count&lt;/em&gt; the number of valid arrangements for the objects. For example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In how many different ways can the letters in B A N A N A be written?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Fourteen construction workers are to be assigned to three different tasks. Seven workers are needed for mixing cement, five for laying bricks,and two for carrying the bricks to the brick layers. In how many different ways can the be assigned to these workers tasks?&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;A shipment of 12 different TVs contains 3 defective ones. In how many ways can a hotel purchase 5 of these TVs and receive at least 2 of the defective ones?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Such problems present two challenges for AI:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;NLP&lt;/em&gt; - Understanding setting, objects, quantities, and the question provided in natural language.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Automated reasoning&lt;/em&gt; - Finding a solving strategy to answer the question from the given information.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this paper we consider a &lt;em&gt;two-step approach&lt;/em&gt; to solving combinatorics math word problems.
The two-step approach addresses the two AI challenges in two stages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;translating the problem expressed in natural language in a formal, machine-understandable language,&lt;/li&gt;
&lt;li&gt;applying automated reasoning methods (solver) to the formalization of the problem to infer the solution.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Two steps&#34;
           src=&#34;http://localhost:41063/publication/coso/twostep.svg&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This approach showed more promising results on similar tasks than an &lt;em&gt;end-to-end&lt;/em&gt; approach, where a neural network predicts the answer directly from the text. This however showed several limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Poor solving performance (esp. on a small dataset)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Lacking generalizability &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Lacking explainability &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;One step&#34;
           src=&#34;http://localhost:41063/publication/coso/onestep.svg&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In the two-step approach the intermediate language simplifies the task of the neural network by moving the automated reasoning challenge to a logic-based framework, which offers considerably more generalizability and explainability opportunities.
The challenge in a two-step approach is to have an intermediate formal language as expressive as possible, and at the same time to develop (efficient) inference methods for all possible problems expressible in the formal language.
Current declarative frameworks either offer languages that are not expressive enough for the class of problems at hand or inference methods that are very inefficient.&lt;/p&gt;
&lt;p&gt;We address these limitations with the following contributions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CoLa - a formal language to encode combinatorics math word problems,&lt;/li&gt;
&lt;li&gt;CoSo - a solver to automatically (and efficiently) reason over and solve problems expressed in CoLa.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;cola-modelling-combinatorics-math-word-problems&#34;&gt;CoLa: modelling combinatorics math word problems&lt;/h3&gt;
&lt;p&gt;CoLa is a novel declarative language designed to model combinatorics math word problems, for which we also developed efficient reasoning techniques (implemented in the solver CoSo).
Existing declarative language, such as logic-based languages (Answer Set Programming, Prolog,&amp;hellip;) and constraint modelling languages, do not directly support all of the fundamental primitives to encode combinatorics math word problems. The three primitives necessary to formally encode combinatorics math problems are the following.&lt;/p&gt;
&lt;h4 id=&#34;multisets&#34;&gt;Multisets&lt;/h4&gt;
&lt;p&gt;Multisets are collections of objects where any object can have a number of identical copies. For example, the letters in B A N A N A are a multiset where A B and N are the distinguishable objects, and there are 3 identical copies of A and 2 of N.
&lt;img src=&#34;mset.svg&#34; alt=&#34;Multiply&#34; width=&#34;300&#34;/&gt;&lt;/p&gt;
&lt;p&gt;In CoLa multisets, in particular the &lt;em&gt;universe&lt;/em&gt;, can be declared by enumeration, repeating the labels of identical copies, or by specifying the property characterizing the copies and their number (with a &lt;em&gt;size constraint&lt;/em&gt;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;universe&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;letters&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;enumeration&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;property a; property n; property b; % distinguishable properties
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#a=3; #n=2; #b=1; % identical copies
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The keyword &lt;code&gt;labelled&lt;/code&gt; can be used to specify a regular set where all elements are unique&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;labelled property workers;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#workers = 14;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;labelled property tvs;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#tvs = 12;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;labelled property defective;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#defective = 3;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;configurations&#34;&gt;Configurations&lt;/h4&gt;
&lt;p&gt;Configurations define how objects are arranged:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Objects are &lt;em&gt;ordered/unordered&lt;/em&gt; (e.g. sets vs. permutations)&lt;/li&gt;
&lt;li&gt;Objects are placed &lt;em&gt;with or without repetition&lt;/em&gt; (e.g. multisets vs. sets)&lt;/li&gt;
&lt;li&gt;Objects are arranged in a &lt;em&gt;single or multiple groups&lt;/em&gt; (e.g. sets vs. partitions)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CoLa offers several statements to express the most common configurations, based on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Twelvefold_way&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twelvefold-way&lt;/a&gt;&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.
These configurations are fundamental because they can be counted quickly with combinatorial rules, such as factorials or binomial coefficients.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;word in [letters] % a permutation of letters: a word
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;word.svg&#34; alt=&#34;Permutation&#34; width=&#34;500&#34;/&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;groups in [{workers}]; % a composition of workers: an ordered partition 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;partition.svg&#34; alt=&#34;Partition&#34; width=&#34;300&#34;/&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;purchase in {tvs}; % a subset of TVs
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;truck.svg&#34; alt=&#34;Subset&#34; width=&#34;300&#34;/&gt;
&lt;h4 id=&#34;constraints&#34;&gt;Constraints&lt;/h4&gt;
&lt;p&gt;Constraints define restrictions on how objects are arranged in the configuration. While natural language can express virtually any kind of constraint, in CoLa we restrict to few constraints that are interesting in terms of efficient resolution of combinatorics math word problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Size constraints&lt;/em&gt; - define the size of configurations, properties and multisets.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#groups=3; % specify the number of groups of workers
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#tvs&amp;amp;defective = 3; % specify the number of tvs that are defective
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#purchase = 5; % specify the number of purchased TVs 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Positional constraints&lt;/em&gt; - define the properties of objects in specific positions in an ordered configuration.
&lt;img src=&#34;size.svg&#34; alt=&#34;Size constraint&#34; width=&#34;300&#34;/&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-gdscript3&#34; data-lang=&#34;gdscript3&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#groups[1] = 7; % size constraints on the index of the groups of workers&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#groups[2] = 5;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;#groups[3] = 2;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Counting constraints&lt;/em&gt; - define the number of objects in a configuration or subset with the given property.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;#(defective &amp;amp; purchase) &amp;gt;= 2;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&#34;counting.svg&#34; alt=&#34;Counting constraint&#34; width=&#34;300&#34;/&gt;
&lt;h3 id=&#34;coso-reasoning-over-combinatorics-math-word-problems&#34;&gt;CoSo: reasoning over combinatorics math word problems&lt;/h3&gt;
&lt;p&gt;CoSo implements lifted reasoning techniques for combinatorics math word problems. Lifted reasoning exploits high-level symmetries and the interchangeability of objects to efficiently count the number of admissible assignments for a set of variables.
In this paper we implement the principles of &lt;em&gt;probabilistic&lt;/em&gt; lifted reasoning&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; in the context of &lt;em&gt;counting constraint satisfaction problems&lt;/em&gt; (#CSPs).&lt;/p&gt;
&lt;p&gt;Existing declarative frameworks usually resort to &lt;em&gt;propositional&lt;/em&gt; reasoning, that is, enumeration of the solutions or grounding, namely replacing each variable with all possible individual objects in its domain. Therefore, they can be very inefficient on combinatorics math word problems, where the number of solutions is usually exponential in the number of objects.&lt;/p&gt;
&lt;p&gt;CoSo can solve these problems efficiently by applying the following lifted reasoning principles:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multiplication - multiply the solution of two &lt;em&gt;independent&lt;/em&gt; subproblems to lift the count of their combinations.
&lt;img src=&#34;mul.svg&#34; alt=&#34;Multiply&#34; width=&#34;300&#34;/&gt;&lt;/li&gt;
&lt;li&gt;Splitting - decompose a problem into subproblems such that the multiplication principle is applicable.
&lt;img src=&#34;split.svg&#34; alt=&#34;Split&#34; width=&#34;200&#34;/&gt;&lt;/li&gt;
&lt;li&gt;Propositionalization - reason on individual objects when it is not possible to group them.
&lt;img src=&#34;prop.svg&#34; alt=&#34;Propositionalization&#34; width=&#34;300&#34;/&gt;&lt;/li&gt;
&lt;li&gt;Exchangeability - account for any invariance under permutation of the variables.
&lt;img src=&#34;exch.svg&#34; alt=&#34;Exchangeability&#34; width=&#34;300&#34;/&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CoSo applies these principles to decompose a problem in subproblems where the common combinatorial counting rules for the base configurations are applicable.&lt;/p&gt;
&lt;p&gt;With experiments on a real-world dataset and synthetic benchmarks we show that the implementation of these principles can significantly speed-up the computation of the solution of combinatorics math world problems compared to traditional declarative frameworks.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://localhost:41063/publication/dblp-confemnlp-suster-ftkdrd-21/&#34;&gt;S.Suster, P.Fivez, P.Totis, A.Kimmig, J.Davis, L. de Raedt, W.Daelemans, &amp;ldquo;Mapping probability word problems to executable representations&amp;rdquo; EMNLP 2021&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://aclanthology.org/2021.naacl-main.168/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A.Patel, S.Bhattamishra, and N.Goyal, &amp;ldquo;Are NLP Models really able to Solve Simple Math Word Problems?&amp;rdquo;, NAACL 2021&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://openreview.net/pdf?id=H1gR5iR5FX&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;D.Saxton E. Grefenstette F. Hill P. Kohli, &amp;ldquo;Analysing Mathematical Reasoning Abilities of Neural Models&amp;rdquo;, ICLR 2019&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://math.mit.edu/~rstan/ec/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R.Stanley, &amp;ldquo;Enumerative combinatorics&amp;rdquo;, 2012, Cambridge University Press, New York.&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://mitpress.mit.edu/9780262542593/an-introduction-to-lifted-probabilistic-inference/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;G. Van den Broeck, K. Kersting, and S. Natarajan, &amp;ldquo;An Introduction to
Lifted Probabilistic Inference&amp;rdquo;, 2021, The MIT Press.&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Efficient Knowledge Compilation Beyond Weighted Model Counting</title>
      <link>http://localhost:41063/publication/dblp-journalstplp-kiesel-tk-22/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:41063/publication/dblp-journalstplp-kiesel-tk-22/</guid>
      <description></description>
    </item>
    
    <item>
      <title>smProbLog: Stable Model Semantics in ProbLog for Probabilistic Argumentation</title>
      <link>http://localhost:41063/publication/dblp-journalscorrabs-2110-01990/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:41063/publication/dblp-journalscorrabs-2110-01990/</guid>
      <description>&lt;h3 id=&#34;problem&#34;&gt;Problem&lt;/h3&gt;
&lt;p&gt;In this paper we propose a new approach to probabilistic argumentation problems based on probabilistic logic programming (PLP).
Probabilistic argumentation problems augment a traditional &lt;em&gt;abstract argumentation framework&lt;/em&gt; (AAF) with probabilities: nodes are atomic arguments and edges denote the attack relation.
Both arguments and relations can be associated with probabilities.&lt;/p&gt;
&lt;img src=&#34;pargs.svg&#34; width=&#34;600&#34;&gt;
&lt;p&gt;For probabilistic AAFs there are different approaches to define the semantics of probabilities and reasoning techniques specific to probabilistic AAFs.
On the contrary, PLP languages and systems aim at offering general purpose tools to reason and learn in structured domains under uncertainty.
In this paper we address the question as to whether PLP systems can be used to define semantics and reasoning techniques for probabilistic argumentation problems.
Our answer is divided in two parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;a mapping from probabilistic AAFs to probabilistic logic programs;&lt;/li&gt;
&lt;li&gt;a PLP semantics and system, &lt;a href=&#34;https://github.com/PietroTotis/smProblog&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;smProbLog&lt;/a&gt;, which provide reasoning and learning tools suitable to this type of programs.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;what-do-probabilities-mean&#34;&gt;What do probabilities mean?&lt;/h3&gt;
&lt;p&gt;Probabilistic logic programs are logic programs in which some of the facts are annotated with probabilities.
For instance in this program the facts &lt;code&gt;rain&lt;/code&gt; and &lt;code&gt;wind&lt;/code&gt; are &lt;em&gt;probabilistic&lt;/em&gt; because they belong to the program with some probability.
Taking the umbrella or wearing the scarf are inferred from these two facts according to the logic rules.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.4::rain.                  % probabilistic facts
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.7::wind.                   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;umbrella :- rain, not wind. % logic rules
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;scarf :- rain.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;scarf :- wind.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;query(umbrella).            % compute the probability of taking the umbrella
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Distribution semantics&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; define the semantics of probabilities: each probabilistic fact $p::f.$

represents an &lt;em&gt;independent&lt;/em&gt; choice to include or not the fact in the program.
A total choice is a set of choices for all facts: the &lt;em&gt;deterministic&lt;/em&gt; program obtained by combining a total choice with the logical rules is a &lt;em&gt;possible world&lt;/em&gt;.
The probability of success of a query is the sum of the probabilities of the possible worlds where queried atom can be derived to be true.&lt;/p&gt;
&lt;p&gt;In probabilistic AAFs there are two approaches&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; to define the semantics and reasoning techniques of probabilities:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The constellations approach.&lt;/li&gt;
&lt;li&gt;The epistemic approach.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The constellations approach considers probabilities an expression of uncertainty over the structure of the graph.
Similarly to distribution semantics, the probabilities induce a set of possible worlds corresponding to all possible subgraphs.
The probability of a subgraph is the combination of the probabilities of the chosen nodes and edges, and the probability of accepting an argument is the sum of the probabilities of the argument graphs where the argument is acceptable.
&lt;img src=&#34;const.svg&#34;&gt;
This approach however presents two issues regarding semantics:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the independence assumption of including or not an argument in the graph, while the goal of an AAF is to model their dependencies.&lt;/li&gt;
&lt;li&gt;the semantics of the possible worlds where an attack is chosen but one of the two arguments involved is not (e.g. worlds on the right-hand side)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;On the other hand, in the epistemic approach probabilities express &lt;em&gt;degrees of belief&lt;/em&gt; in the arguments, and the structure of the graph is no longer uncertain.
Arguments with probability higher than 0.5 are considered accepted, otherwise rejected.
Reasoning on epistemic argument graphs thus consists in finding a family of probability distribution that satisfies a given set of properties, e.g. coherency, rationality,&amp;hellip;, with respect to the structure of the argument graph.
&lt;img src=&#34;epistemic.svg&#34;&gt;
For example the belief assignment in the picture is not rational because both $a_1$
 and $a_2$
 are accepted, but also the attack between the two receives a high degree of belief.&lt;/p&gt;
&lt;p&gt;By mapping probabilistic argument graphs to PLP we introduce a novel perspective which combines the two approaches.
We model explicitly degrees of belief as in the epistemic approach, but we reason over this uncertainty with probabilistic logic programs and the distributions semantics, thus in terms of possible worlds as in the constellations approach.
The key points of our approach are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The probability of an argument represents a belief bias &lt;em&gt;independent&lt;/em&gt; of other arguments.
It summarizes all the epistemic effects of the supporters of an argument which are not relevant to represent explicitly.&lt;/li&gt;
&lt;li&gt;An attack $(a,b)$
 with probability $p$
 defines an &lt;em&gt;inhibition&lt;/em&gt; of the belief in $b$
 proportional to $p$
 when $a$ is believed.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;mapping-probabilistic-aafs-to-plp&#34;&gt;Mapping probabilistic AAFs to PLP&lt;/h3&gt;
&lt;p&gt;Judea Pearl&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; remarks how the combination of probability theory and graphs representing context dependencies are fundamental to model beliefs:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We will also stress that probability theory is unique in its ability to process context-sensitive beliefs, and what makes the processing computationally feasible is that the information needed for specifying context dependencies can be represented by graphs and manipulated by local propagation.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We follow this principle in interpreting the argument graph as the representation of context dependencies between arguments:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We map arguments to logical atoms that are inferred from logical rules&lt;/li&gt;
&lt;li&gt;We map arguments&amp;rsquo; probabilities to probabilistic facts which model a bias independent of other arguments. Any argument can be inferred from its bias.&lt;/li&gt;
&lt;li&gt;We map attacks to logic rules with &lt;em&gt;negation in the head&lt;/em&gt; annotated with the attack&amp;rsquo;s probability.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.6::bias(hotel_X).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.8::bias(hotel_Y).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.4::bias(expensive).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.2::bias(noise).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;arg(X) :- bias(X).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.7::¬arg(hotel_Y) :- arg(hotel_X).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.4::¬arg(hotel_X) :- arg(hotel_Y).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.8::¬arg(hotel_Y) :- arg(noise).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.9::¬arg(hotel_X) :- arg(expensive).
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;query(arg(X)).
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Annotated rules are a syntactic feature that is equivalent to an additional probabilistic fact in the body, for instance:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.8::umbrella :- rain, not wind.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;is equivalent to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.8 :: remember.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;umbrella :- remember, rain, not wind.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Moreover, negation in the head models the so-called &lt;em&gt;inhibition effect&lt;/em&gt;, which expresses an inhibition of the belief of the head of the rule proportional to its probability.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.3::friend_brings_umbrella.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;¬umbrella :- friend_brings_umbrella.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;is internally rewritten as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0.3::friend_brings_umbrella.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;umbrella :- umbrella_pos, umbrella_neg.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;umbrella_pos :- remember, rain, not wind.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;umbrella_neg :- friend_brings_umbrella.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div style=&#34;display:flex;&#34;&gt;
&lt;img src=&#34;IE1.svg&#34; width=&#34;400&#34; style=&#34;margin-left:-10%&#34;&gt;
&lt;img src=&#34;IE2.svg&#34; width=&#34;400&#34; style=&#34;margin-left:-30%&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Moreover, the flexibility and expressivity of PLP can be exploited to encode more complex argumentation problems than basic AFFs, for instance expressing supports with regular rules (as with bias) or joint attacks or supports with rules with multiple arguments in the body.&lt;/p&gt;
&lt;h3 id=&#34;the-joint-probability-distribution&#34;&gt;The joint probability distribution&lt;/h3&gt;
&lt;p&gt;The programs obtained from this mapping define a &lt;em&gt;joint probability distribution&lt;/em&gt; over the arguments.
The joint probability (belief) distribution induced by the argument graph resembles the description of N. Nilsson&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; of how humans reason over beliefs:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If we were to examine the relationships among all of our beliefs carefully, an impossible task in practice but one that is interesting to think about, we would see that some of them should make others more credible and some less. They would even compete among themselves with conflicting influences. We can imagine all of the beliefs in our large network of beliefs “fighting it out” to agree finally on the strength of each belief in the network. When they do finally agree, we say that the beliefs cohere.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The joint probability distribution can be analyzed with the typical PLP tools and algorithms offered by PLP systems.
Conditional probabilities, expressed by means of &lt;em&gt;evidence&lt;/em&gt;, can be queried to study how the beliefs change when new information about the truth of the arguments is provided.&lt;/p&gt;
&lt;iframe src=&#34;http://localhost:41063/belief.html&#34; title=&#34;Beliefs animation&#34; height=&#34;400&#34; width=&#34;700&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;
Most probable explanation (MPE) queries return the most probable possible world where the given evidence holds. 
They can thus be used to find the set of beliefs which contribute the most to believing one or more arguments.
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://rjida.meijo-u.ac.jp/reference/ICLP95.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;T. Sato, &amp;ldquo;A Statistical Learning Method for Logic Programs with Distribution Semantics&amp;rdquo;, ICLP 1995.&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://www0.cs.ucl.ac.uk/staff/a.hunter/papers/ijar12.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A. Hunter, &amp;ldquo;A probabilistic approach to modelling uncertain logical arguments&amp;rdquo;, Int. J. Approx. Reasoning, 2013&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://dl.acm.org/doi/10.5555/534975&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;J. Pearl, &amp;ldquo;Probabilistic reasoning in intelligent systems: networks of plausible inference&amp;rdquo;, Rev. 2. ed. Morgan Kaufmann, 2009&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://mitpress.mit.edu/9780262526432/understanding-beliefs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;N. Nilsson, &amp;ldquo;Understanding Beliefs.&amp;rdquo;, The MIT Press Essential Knowledge series. MIT Press, 2014&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
